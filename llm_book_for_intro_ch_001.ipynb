{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMl4R/m3QpM961JAbrXyQp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enginearn/llm_book_for_intro/blob/main/llm_book_for_intro_ch_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1"
      ],
      "metadata": {
        "id": "Y2s56jFuljOA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J7YS8bIlgyK",
        "outputId": "f30d259d-0ee8-4ced-b673-fb98a2f092d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[ja,sentencepiece,torch] in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (4.65.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (0.21.0)\n",
            "Requirement already satisfied: fugashi>=1.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (1.2.1)\n",
            "Requirement already satisfied: ipadic<2.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (1.0.0)\n",
            "Requirement already satisfied: unidic-lite>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (1.0.8)\n",
            "Requirement already satisfied: unidic>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (1.1.0)\n",
            "Requirement already satisfied: sudachipy>=0.6.6 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (0.6.7)\n",
            "Requirement already satisfied: sudachidict-core>=20220729 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (20230110)\n",
            "Requirement already satisfied: rhoknp<1.3.1,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (1.3.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[ja,sentencepiece,torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[ja,sentencepiece,torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[ja,sentencepiece,torch]) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,sentencepiece,torch]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,sentencepiece,torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,sentencepiece,torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[ja,sentencepiece,torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[ja,sentencepiece,torch]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[ja,sentencepiece,torch]) (16.0.6)\n",
            "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from unidic>=1.0.2->transformers[ja,sentencepiece,torch]) (0.10.1)\n",
            "Requirement already satisfied: plac<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from unidic>=1.0.2->transformers[ja,sentencepiece,torch]) (1.3.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja,sentencepiece,torch]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja,sentencepiece,torch]) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja,sentencepiece,torch]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja,sentencepiece,torch]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[ja,sentencepiece,torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[ja,sentencepiece,torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[ja,sentencepiece,torch]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "huSufkxgl69D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text classification"
      ],
      "metadata": {
        "id": "tc7MMOtipvfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.tools import text_classification\n",
        "text_classification_pipeline = pipeline(\n",
        "    model=\"llm-book/bert-base-japanese-v3-marc_ja\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjJ_0VjRnCr4",
        "outputId": "68140050-95d4-42a9-f5c3-bff0b0cee179"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_text = \"明日は明日の風が吹く\"\n",
        "print(text_classification_pipeline(positive_text)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7Oya6YdpgrY",
        "outputId": "959c088d-edc6-439e-9c2e-69150a9b44aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'positive', 'score': 0.998440682888031}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_text = \"お金がなさ過ぎてつらい...\"\n",
        "print(text_classification_pipeline(negative_text)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-tN8W5yoEnE",
        "outputId": "fb46b5fd-0653-4fcd-b35a-bfe4be9dbc9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'negative', 'score': 0.9948321580886841}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Inference: 自然言語推論"
      ],
      "metadata": {
        "id": "XQbp_V61p_yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nli_pipline = pipeline(model=\"llm-book/bert-base-japanese-v3-jnli\")"
      ],
      "metadata": {
        "id": "8vxrCDpPpJuf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`entailment`は`含意`であり、\"二人の女性が山を眺めています\"が成立するならば、\"山を眺めている人が2人います\"も成立するという関係を表す。"
      ],
      "metadata": {
        "id": "nM3AfEmNx9-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"二人の女性が山を眺めています\"\n",
        "entailment_text = \"山を眺めている人が2人います\"\n",
        "\n",
        "print(nli_pipline({\"text\": text, \"text_pair\": entailment_text}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJokfd-lqd8r",
        "outputId": "f49a6837-086f-4e9f-aa78-82c4d7c17db4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'entailment', 'score': 0.9933545589447021}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`contradiction`は、`矛盾`"
      ],
      "metadata": {
        "id": "LEGVIAsRyunI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contradiction_text = \"女性２人が山を破壊しています\"\n",
        "\n",
        "print(nli_pipline({\"text\": text, \"text_pair\": contradiction_text}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmLN1ZEhwOvJ",
        "outputId": "0144708d-3d93-4474-fded-976cce7ee16d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'contradiction', 'score': 0.9771778583526611}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neutral_text = \"女性２人が山で料理をしています\"\n",
        "\n",
        "print(nli_pipline({\"text\": text, \"text_pair\": neutral_text}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCLi0Ulxw3c9",
        "outputId": "b55a0cd2-146e-43c5-9bf4-f063ffbef701"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'neutral', 'score': 0.9970123767852783}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic textual similarity: STS\n",
        "\n",
        "二つのテキストが似ている度合いをスコアとして予測するタスク"
      ],
      "metadata": {
        "id": "s-gGTaGIzYvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_sts_pipeline = pipeline(\n",
        "    model=\"llm-book/bert-base-japanese-v3-jsts\",\n",
        "    function_to_apply=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "4aSzRJzrzLmH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"マチュピチュにはマヤ文明がありました\"\n",
        "sim_text = \"ストーンヘンジにはドルイド文明が存在していました。\"\n",
        "\n",
        "result = text_sts_pipeline({\"text\": text, \"text_pair\": sim_text})\n",
        "print(result[\"score\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vuK9N1G0jfO",
        "outputId": "267dcb25-2713-44d1-8a2e-0f08a91acb60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0985182523727417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim_text = \"マチュピチュはマヤ文明の一部でした。\"\n",
        "\n",
        "result = text_sts_pipeline({\"text\": text, \"text_pair\": sim_text})\n",
        "print(result[\"score\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "990Eryma4BD-",
        "outputId": "7eaabe93-ecb6-4e9b-bc6e-83ee3b982950"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.884174346923828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dissim_text = \"トイレの壁に黒いタオルがかけられています\"\n",
        "\n",
        "result = text_sts_pipeline({\"text\": text, \"text_pair\": dissim_text})\n",
        "print(result[\"score\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqwb8sxp4mQ5",
        "outputId": "b594e021-c498-4cfd-bead-a0e02e08bafc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.05538347363471985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "sim_enc_pipeline = pipeline(\n",
        "    model=\"llm-book/bert-base-japanese-v3-unsup-simcse-jawiki\",\n",
        "    task=\"feature-extraction\",\n",
        ")"
      ],
      "metadata": {
        "id": "eqU6zH024636"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# textとsim_textのベクトルを獲得\n",
        "text_emb = sim_enc_pipeline(text, return_tensors=True)[0][0]\n",
        "sim_emb = sim_enc_pipeline(sim_text, return_tensors=True)[0][0]\n",
        "# textとsim_textの類似度を計算\n",
        "sim_pair_score = cosine_similarity(text_emb, sim_emb, dim=0)\n",
        "print(sim_pair_score.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwyg4XBy50AL",
        "outputId": "d8b84e31-68da-4fe3-9c5a-2d2e086bf1a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9352689385414124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dissim_textのベクトルを獲得\n",
        "dissim_emb = sim_enc_pipeline(dissim_text, return_tensors=True)[0][0]\n",
        "# textとdissim_textの類似度を計算\n",
        "dissim_pair_score = cosine_similarity(text_emb, dissim_emb, dim=0)\n",
        "print(dissim_pair_score.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYJD2spL8I3w",
        "outputId": "1eb1e70e-c9c8-46d4-d68f-e31f07e6cec1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.33561891317367554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Named entity recognition: NER\n",
        "\n",
        "テキストに含まれる固有表現を抽出するタスク"
      ],
      "metadata": {
        "id": "3eP5NpVo8fmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "ner_pipeline = pipeline(\n",
        "    model=\"llm-book/bert-base-japanese-v3-ner-wikipedia-dataset\",\n",
        "    aggregation_strategy=\"simple\",\n",
        ")"
      ],
      "metadata": {
        "id": "FJB-SxvM8Xti"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"大谷翔平は岩手県水沢市出身のプロ野球選手です\"\n",
        "pprint(ner_pipeline(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Is82RGdCmx",
        "outputId": "71fe27cc-025d-4b69-95d1-eab58f931b66"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'end': None,\n",
            "  'entity_group': '人名',\n",
            "  'score': 0.99822515,\n",
            "  'start': None,\n",
            "  'word': '大谷 翔平'},\n",
            " {'end': None,\n",
            "  'entity_group': '地名',\n",
            "  'score': 0.9987048,\n",
            "  'start': None,\n",
            "  'word': '岩手 県 水沢 市'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarization generation"
      ],
      "metadata": {
        "id": "qyRgX4hhefVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2text_pipeline = pipeline(\n",
        "    model=\"llm-book/t5-base-long-livedoor-news-corpus\"\n",
        ")"
      ],
      "metadata": {
        "id": "7-7hnkR2eQHw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"\"\"\n",
        "生成型AIは、テキスト、画像、音楽、さらには映画など、広範なデータ種類に対して複雑なパターンを学習し、新たなコンテンツを創出することが可能です。GPT-4のような最新のモデルは、既に驚くべき精度と多様性を持っていますが、さらなる進化が期待されます。\n",
        "まず、生成型AIのモデルはより洗練され、特定のタスクや要求に対する独自の「スタイル」を持つことが可能になるでしょう。これは、ユーザーがAIに「詩人のように書く」や「特定のアーティストの風格で絵を描く」など、より具体的な要求をすることを可能にします。\n",
        "次に、モデルは予測の質と適用範囲をさらに向上させることが期待されます。例えば、個々の言葉やフレーズだけでなく、全体的な会話や物語の文脈を理解し、それに対応した生成を行うことが可能になるでしょう。\n",
        "さらに、生成型AIは個々のユーザーとの対話から学習し、ユーザーの嗜好や要求により適応する能力を強化する可能性があります。これにより、個々のユーザーにとってより有用でパーソナライズされた体験が提供されます。\n",
        "最後に、AIの進化は倫理的な問題も提起します。AIが創造するコンテンツの著作権やプライバシー保護、偏見の排除など、新たな課題に立ち向かうためのガイドラインや規制の必要性が強まってきています。これらの課題を解決することで、生成型AIの今後はさらに明るいものとなるでしょう。\n",
        "\"\"\"\n",
        "\n",
        "print(text2text_pipeline(article)[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2f8NAi1fHdQ",
        "outputId": "10e8ed36-de5e-40fb-efb6-949d539b150b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "進化するAI GPT-4 AIの未来【デジ通】\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- machine translation\n",
        "- dialogue system\n",
        "- morphological analysis\n",
        "- parsing\n",
        "- coreference resolution"
      ],
      "metadata": {
        "id": "x3fYVMzfhe9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "Te9kT4y9h5UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"abeja/gpt2-large-japanese\")\n",
        "\n",
        "tokenizer.tokenize(\"今日は天気が良いので\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzM0-lAbhI4H",
        "outputId": "f7fc5617-0187-44db-dab6-04122233f37d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁', '今日', 'は', '天気', 'が良い', 'の', 'で']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"abeja/gpt2-large-japanese\"\n",
        ")\n",
        "\n",
        "inputs = tokenizer(\"今日は天気が良いので\", return_tensors=\"pt\")\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_length=30,\n",
        "    pad_token_id=tokenizer.pad_token_id\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(\n",
        "    outputs[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "U4c3FYgLlLJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "32T0gNAV1R3H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}